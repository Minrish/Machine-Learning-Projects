{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__-C%3A-Users-ybxYB-AppData-Local-Temp-ipykernel-2389174336.get_data...\n",
      "get_data()\n",
      "_________________________________________________________get_data - 0.1s, 0.0min\n",
      "[0.83660934 0.84930385 0.84848485 0.8495086  0.84725635]\n",
      "Accuracy: 84.62325962325963\n"
     ]
    }
   ],
   "source": [
    "# Model No. 1 XGBoost model for a9a\n",
    "from xgboost import XGBClassifier\n",
    "from joblib import Memory\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "mem = Memory(\"./mycache\")\n",
    "\n",
    "@mem.cache\n",
    "def get_data():\n",
    "    data = load_svmlight_file('a9a.txt')\n",
    "    return data[0], data[1]\n",
    "\n",
    "X, y = get_data()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=5)\n",
    "model = XGBClassifier()\n",
    "results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(results)\n",
    "print(\"Accuracy:\", results.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=9, min_child_weight=5\n",
      "\tMAE 0.22150157693369535 for 9 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "\tMAE 0.2208557691286073 for 9 rounds\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\tMAE 0.22094374956897012 for 9 rounds\n",
      "CV with max_depth=10, min_child_weight=5\n",
      "\tMAE 0.22027006083297565 for 9 rounds\n",
      "CV with max_depth=10, min_child_weight=6\n",
      "\tMAE 0.220619138947599 for 9 rounds\n",
      "CV with max_depth=10, min_child_weight=7\n",
      "\tMAE 0.22018703737121303 for 9 rounds\n",
      "CV with max_depth=11, min_child_weight=5\n",
      "\tMAE 0.22013897871428223 for 9 rounds\n",
      "CV with max_depth=11, min_child_weight=6\n",
      "\tMAE 0.21952606973274613 for 9 rounds\n",
      "CV with max_depth=11, min_child_weight=7\n",
      "\tMAE 0.21955544958041515 for 9 rounds\n",
      "Best params: 11, 6, MAE: 0.21952606973274613\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "params = {\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'objective':'reg:squarederror',\n",
    "}\n",
    "\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]\n",
    "\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        metrics={'mae'},\n",
    "    )\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83353808 0.84725635 0.83947584 0.84234234 0.84295659]\n",
      "Accuracy: 84.11138411138411\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits=5)\n",
    "model = XGBClassifier(max_depth=11, min_child_weight=5)\n",
    "results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(results)\n",
    "print(\"Accuracy:\", results.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83435708 0.8495086  0.84254709 0.8454136  0.84725635]\n",
      "Accuracy: 84.38165438165439\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits=5)\n",
    "model = XGBClassifier(max_depth=7, min_child_weight=5)\n",
    "results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(results)\n",
    "print(\"Accuracy:\", results.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "[0.83660934 0.84930385 0.84848485 0.8495086  0.84725635]\n",
      "Accuracy: 84.62325962325963\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits=5)\n",
    "model = XGBClassifier(tree_method = \"exact\")\n",
    "results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(model)\n",
    "print(results)\n",
    "print(\"Accuracy:\", results.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "[0.83660934 0.84930385 0.84848485 0.8495086  0.84725635]\n",
      "Accuracy: 84.62325962325963\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits=5)\n",
    "model = XGBClassifier(tree_method = \"approx\")\n",
    "results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(model)\n",
    "print(results)\n",
    "print(\"Accuracy:\", results.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "[0.83660934 0.84930385 0.84848485 0.8495086  0.84725635]\n",
      "Accuracy: 84.62325962325963\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits=5)\n",
    "model = XGBClassifier(tree_method = \"hist\")\n",
    "results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(model)\n",
    "print(results)\n",
    "print(\"Accuracy:\", results.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "[0.83660934 0.84930385 0.84848485 0.8495086  0.84725635]\n",
      "Accuracy: 84.62325962325963\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits=5)\n",
    "model = XGBClassifier(tree_method = \"gpu_hist\")\n",
    "results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(model)\n",
    "print(results)\n",
    "print(\"Accuracy:\", results.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n",
      "\tMAE 0.21955544958041515 for 9 rounds\n",
      "Best params: 1.0, 1.0, MAE: 0.21955544958041515\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tMAE 0.22035508879788282 for 9 rounds\n",
      "Best params: 1.0, 1.0, MAE: 0.21955544958041515\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tMAE 0.220875164812945 for 9 rounds\n",
      "Best params: 1.0, 1.0, MAE: 0.21955544958041515\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tMAE 0.22172634295982774 for 9 rounds\n",
      "Best params: 1.0, 1.0, MAE: 0.21955544958041515\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tMAE 0.2197924116190039 for 9 rounds\n",
      "Best params: 1.0, 1.0, MAE: 0.21955544958041515\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tMAE 0.22037085983194762 for 9 rounds\n",
      "Best params: 1.0, 1.0, MAE: 0.21955544958041515\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tMAE 0.22102017096936902 for 9 rounds\n",
      "Best params: 1.0, 1.0, MAE: 0.21955544958041515\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tMAE 0.22254947214156387 for 9 rounds\n",
      "Best params: 1.0, 1.0, MAE: 0.21955544958041515\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tMAE 0.22039710569299756 for 9 rounds\n",
      "Best params: 1.0, 1.0, MAE: 0.21955544958041515\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tMAE 0.22099955694996035 for 9 rounds\n",
      "Best params: 1.0, 1.0, MAE: 0.21955544958041515\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tMAE 0.2214875856772336 for 9 rounds\n",
      "Best params: 1.0, 1.0, MAE: 0.21955544958041515\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tMAE 0.22279265946542723 for 9 rounds\n",
      "Best params: 1.0, 1.0, MAE: 0.21955544958041515\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tMAE 0.22077781800706497 for 9 rounds\n",
      "Best params: 1.0, 1.0, MAE: 0.21955544958041515\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tMAE 0.22020112702772796 for 9 rounds\n",
      "Best params: 1.0, 1.0, MAE: 0.21955544958041515\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tMAE 0.2222994956135822 for 9 rounds\n",
      "Best params: 1.0, 1.0, MAE: 0.21955544958041515\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tMAE 0.22278934479908238 for 9 rounds\n",
      "Best params: 1.0, 1.0, MAE: 0.21955544958041515\n"
     ]
    }
   ],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]\n",
    "\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        metrics={'mae'}\n",
    "    )\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "        \n",
    "    print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "[0.83415233 0.8503276  0.84438984 0.84438984 0.8454136 ]\n",
      "Accuracy: 84.37346437346436\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits=5)\n",
    "model = XGBClassifier(subsample=.8,colsample_bytree=1)\n",
    "results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(model)\n",
    "print(results)\n",
    "print(\"Accuracy:\", results.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "CV with eta=0.3\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "\tMAE 0.2165687118544144 for 15 rounds\n",
      "\n",
      "CV with eta=0.2\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "\tMAE 0.21477705422362708 for 27 rounds\n",
      "\n",
      "CV with eta=0.1\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "\tMAE 0.2131775849792296 for 65 rounds\n",
      "\n",
      "CV with eta=0.05\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "\tMAE 0.21195645594433182 for 135 rounds\n",
      "\n",
      "CV with eta=0.01\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "\tMAE 0.2111709065043037 for 666 rounds\n",
      "\n",
      "CV with eta=0.005\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "\tMAE 0.21223862636901064 for 998 rounds\n",
      "\n",
      "Best params: 0.01, MAE: 0.2111709065043037\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    params['eta'] = eta\n",
    "    %time \n",
    "    cv_results = xgb.cv(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=999,\n",
    "            seed=42,\n",
    "            nfold=5,\n",
    "            metrics=['mae'],\n",
    "            early_stopping_rounds=10\n",
    "    )\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False, eta=0.01,\n",
      "              eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=11, max_leaves=None,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, ...)\n",
      "[0.83579034 0.84377559 0.8450041  0.83804259 0.84275184]\n",
      "Accuracy: 84.10728910728909\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits=5)\n",
    "model = XGBClassifier(max_depth=11, min_child_weight=6, subsample=.8,colsample_bytree=1, eta = 0.01)\n",
    "results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(model)\n",
    "print(results)\n",
    "print(\"Accuracy:\", results.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eta=0.01, eval_metric=None,\n",
      "              feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, ...)\n",
      "[0.82882883 0.84418509 0.84009009 0.83558559 0.83783784]\n",
      "Accuracy: 83.73054873054872\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits=5)\n",
    "model = XGBClassifier(eta = 0.01)\n",
    "results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(model)\n",
    "print(results)\n",
    "print(\"Accuracy:\", results.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 14.65%\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(max_depth = 7, min_child_weight=5)\n",
    "model.fit(X_train, y_train)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__-C%3A-Users-ybxYB-AppData-Local-Temp-ipykernel-1943477679.get_test...\n",
      "get_test()\n",
      "_________________________________________________________get_test - 0.0s, 0.0min\n",
      "Accuracy: 14.44%\n"
     ]
    }
   ],
   "source": [
    "@mem.cache\n",
    "def get_test():\n",
    "    data = load_svmlight_file('a9a.t')\n",
    "    return data[0], data[1]\n",
    "\n",
    "X_test, y_test = get_test()\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "clf = XGBClassifier(max_depth = 7, min_child_weight=5)\n",
    "clf.fit(X, y)\n",
    "\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9dd8ebb00fe7c85347c6025f51a8b0e304af83251ab0a55111d55a85f59e487b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
